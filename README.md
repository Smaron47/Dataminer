====================================================================
                        Excel Scraping Documentation
====================================================================

Project Title: Excel Data Scraper using BeautifulSoup, Requests, and XlsxWriter
Developed by: Smaron Biswas
License: MIT
Year: 2024

--------------------------------------------------------------------
OVERVIEW
--------------------------------------------------------------------
This Python project scrapes data from the website "https://biod.co.uk/stockists/stores" 
using the Requests and BeautifulSoup libraries, processes the scraped data, and then 
writes the information to an Excel spreadsheet using the XlsxWriter module.

The script performs the following tasks:
  • Makes an HTTP GET request to retrieve HTML content.
  • Parses HTML to locate specific div elements (with class "map-marker d-none") 
    that contain stockist details.
  • Extracts store name, latitude/longitude information, detailed text, and hyperlink data.
  • Processes and cleans the extracted text.
  • Writes the cleaned and categorized data into a structured Excel spreadsheet 
    (spreadsheet.xlsx) in a designated worksheet.

SEO Keywords: Web Scraping, BeautifulSoup, Requests, Python Excel, XlsxWriter, Data Extraction, 
             Stockist Data, HTML Parsing, Website Data Scraping, Python Automation

--------------------------------------------------------------------
FEATURES
--------------------------------------------------------------------
1. Data Extraction:
   - Retrieves HTML content from a live website using the Requests module.
   - Utilizes BeautifulSoup to parse and filter HTML elements by class names.
   - Extracts multiple data points: store names, addresses, phone numbers, additional details,
     latitude and longitude, and hyperlinks.

2. Data Cleaning:
   - Processes the raw scraped data to remove empty strings.
   - Splits and cleans multiline text data for proper formatting in the output.

3. Data Export:
   - Uses XlsxWriter to create an Excel workbook and add a worksheet.
   - Writes multiple columns of the processed data into the Excel file.
   - Handles exceptions gracefully by providing default placeholder text when data is missing.

4. Modular and Extensible:
   - The script is divided into functions (e.g., rma) to process lists.
   - The design makes it easy to modify selectors or output formats as needed.

--------------------------------------------------------------------
PROJECT STRUCTURE
--------------------------------------------------------------------
The entire project is contained within a single Python script, and the output Excel file is generated 
in the same directory. Example structure:

  /your-project-directory/
    ├── document.txt         # This documentation file
    ├── scraper.py           # Python script with the code below
    └── spreadsheet.xlsx     # Excel output file generated by the script

--------------------------------------------------------------------
CODE WALKTHROUGH & ANALYSIS
--------------------------------------------------------------------
1. Library Imports:
   - The script imports BeautifulSoup from the bs4 module for HTML parsing.
   - The Requests module handles HTTP requests.
   - The XlsxWriter module is used to create and format the Excel spreadsheet.

2. Excel Workbook Setup:
   - A new workbook ("spreadsheet.xlsx") is created along with a worksheet titled "linked2".

3. Data Cleaning Function (rma):
   - Function "rma(dl)" iterates over a list, removes empty string entries, and returns the cleaned list.
   - Ensures that the data list used later for Excel writing is free from extraneous blanks.

4. Web Scraping:
   - The script sends a GET request to "https://biod.co.uk/stockists/stores" to fetch HTML content.
   - BeautifulSoup parses the HTML and finds all div elements with class "map-marker d-none".

5. Data Extraction Loop:
   - Iterates over each matched element (req):
       • Appends store details (r.text) into a list.
       • Extracts the store name from a nested div element (class "card-header font-weight-bold lh-1 px-2").
       • Retrieves the latitude/longitude from the "data-latlong" attribute.
       • Extracts additional details from a nested div element (class "card-body rounded-0 m-0 lh-1 p-2") 
         and processes the text.
       • Extracts a hyperlink from within the element.
   - Applies conditional logic based on the length of the details list to write specific columns.
   - Uses try/except blocks to handle missing data gracefully, writing placeholder text (".................") 
     when a data point is missing.

6. Writing to Excel:
   - The script writes various data points into distinct columns in the worksheet.
   - Data includes store name, cleaned details, latitude/longitude, and hyperlinks.
   - The row variable is incremented after processing each record.

7. Finalizing the Output:
   - After looping through all records, the workbook is closed, finalizing the Excel file.
   - The total number of elements processed is printed to the console.

SEO Keywords: HTML Parsing, Data Extraction, Excel Generation, Python XlsxWriter, Data Cleaning, 
             Web Automation, Error Handling, Exception Management

--------------------------------------------------------------------
INSTALLATION & USAGE
--------------------------------------------------------------------
1. Prerequisites:
   - Python 3.x installed.
   - Install necessary libraries:
       pip install beautifulsoup4 requests xlsxwriter

2. Running the Script:
   - Save the code in a file (e.g., scraper.py) in your project directory.
   - Open your terminal, navigate to the directory, and run:
       python scraper.py
   - Check the project directory for the generated "spreadsheet.xlsx" file.

SEO Keywords: Installation, Python Setup, BeautifulSoup Installation, Requests Module, XlsxWriter Installation

--------------------------------------------------------------------
TROUBLESHOOTING & CUSTOMIZATION
--------------------------------------------------------------------
- If data isn’t being written correctly, verify the HTML structure of the target URL as website 
  layouts may change.
- Adjust the cleaning function "rma()" or the split logic if the text format differs.
- Modify the output column indexing if additional data points need to be recorded.
- Increase exception handling for specific data extraction failures as needed.

SEO Keywords: Debugging, Troubleshooting, Customization, Script Modification, HTML Layout Changes

--------------------------------------------------------------------
CONCLUSION
--------------------------------------------------------------------
This Excel Data Scraper is a robust tool for web data extraction and Excel reporting. It combines 
the versatility of BeautifulSoup and Requests with the powerful formatting capabilities of XlsxWriter, 
allowing the automated collection and organization of website data into structured Excel files.

By employing modular functions, comprehensive error handling, and flexible design, the script is highly 
adaptable for future enhancements or integration with other data processing workflows.

SEO Keywords Recap: Web Scraping, Excel Generation, BeautifulSoup, Requests, XlsxWriter, Python Automation,
                      Data Extraction, HTML Parsing, Spreadsheet Reporting

====================================================================
                   END OF DOCUMENTATION
====================================================================
